<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  <title> - </title>
  <link rel="stylesheet" href="http://localhost:4000/cronkite-docs/assets/css/just-the-docs.css">
  
  <script type="text/javascript" src="http://localhost:4000/cronkite-docs/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="http://localhost:4000/cronkite-docs/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>


  <div class="page-wrap">
    <div class="side-bar">
      <a href="http://localhost:4000/cronkite-docs" class="site-title fs-6 lh-tight"></a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav>
  <ul class="navigation-list">
    
    
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/cronkite-docs/" class="navigation-list-link">Home</a>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/cronkite-docs/general" class="navigation-list-link">General resources</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/cronkite-docs/general/math-stats/math-stats.html" class="navigation-list-link">Math and stats</a>
                      
                        
                        <ul class="navigation-list-child-list">
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                              <li class="navigation-list-item ">
                                <a href="http://localhost:4000/cronkite-docs/general/math-stats/newsroom-math.html" class="navigation-list-link">Newsroom math and stats review</a>
                              </li>
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                        </ul>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/cronkite-docs/general/data-diary.html" class="navigation-list-link">Data diaries</a>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
              </ul>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/cronkite-docs/excel" class="navigation-list-link">Excel</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/cronkite-docs/excel/xlguides" class="navigation-list-link">Excel guides</a>
                      
                        
                        <ul class="navigation-list-child-list">
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                              <li class="navigation-list-item ">
                                <a href="http://localhost:4000/cronkite-docs/excel/xlguides/xl-refresher.html" class="navigation-list-link">Excel refresher</a>
                              </li>
                            
                          
                            
                              <li class="navigation-list-item ">
                                <a href="http://localhost:4000/cronkite-docs/excel/xlguides/xl-mathreview.html" class="navigation-list-link">Excel math review</a>
                              </li>
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                              <li class="navigation-list-item ">
                                <a href="http://localhost:4000/cronkite-docs/excel/xlguides/xl-tidydata.html" class="navigation-list-link">Tidy data</a>
                              </li>
                            
                          
                            
                          
                            
                          
                            
                          
                        </ul>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/cronkite-docs/excel/xlpractice" class="navigation-list-link">Excel practice</a>
                      
                        
                        <ul class="navigation-list-child-list">
                          
                            
                          
                            
                          
                            
                              <li class="navigation-list-item ">
                                <a href="http://localhost:4000/cronkite-docs/excel/practice/excel-pivot-pools.html" class="navigation-list-link">Swimming pool inspections</a>
                              </li>
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                              <li class="navigation-list-item ">
                                <a href="http://localhost:4000/cronkite-docs/excel/practice/excel-azpop-exercise.html" class="navigation-list-link">Arizona population exercise</a>
                              </li>
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                            
                          
                        </ul>
                      
                    </li>
                  
                
                  
                
                  
                
              </ul>
            
          </li>
        
      
    
      
        
      
    
      
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/cronkite-docs/r-stats/rstats.html" class="navigation-list-link">R for journalism</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
              </ul>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/cronkite-docs/workshops" class="navigation-list-link">Workshops</a>
            
              
              <ul class="navigation-list-child-list ">
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/cronkite-docs/workshops/cronkite-mayo.html" class="navigation-list-link">Cronkite-Mayo</a>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                    <li class="navigation-list-item ">
                      
                      <a href="http://localhost:4000/cronkite-docs/workshops/phd-sources.html" class="navigation-list-link">Links to source data for doctoral students</a>
                      
                    </li>
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
                  
                
              </ul>
            
          </li>
        
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap">
      <div class="page-header">
        <div class="main-content">
          
          <div class="search js-search">
            <div class="search-input-wrap">
              <input type="text" class="js-search-input search-input" placeholder="Search " aria-label="Search " autocomplete="off">
              <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg>
            </div>
            <div class="js-search-results search-results-wrap"></div>
          </div>
          
          
            <ul class="list-style-none text-small mt-md-1 mb-md-1 pb-4 pb-md-0 js-aux-nav aux-nav">
              
                <li class="d-inline-block my-0"><a href="//github.com/pmarsceill/just-the-docs">Just the Docs on GitHub</a></li>
              
            </ul>
          
        </div>
      </div>
      <div class="main-content">
        
          
        
        <div class="page-content">
          {
  "0": {
    "id": "0",
    "title": "Bulletproofing",
    "content": "Bulletproofing the data projectHere are some handouts on avoiding data errors in stories (all from IRE, so you’ll need to sign in):      “Editing the data-driven story,” by Maud Beelman now at the Associated Press:http://ire.org/resource-center/tipsheets/4045/download/?fileid=3950&amp;gt;    DANGER! Look out for Dirty Data, by Jaimi Dowdell now at Reuters http://ire.org/resource-center/tipsheets/3999/download/?fileid=3905  “A Guide to Bulletproofing Your Data,” by Jennifer LaFleur, now at the Investigative Reporting Workshop at American University: http://ire.org/resource-center/tipsheets/3848/download/?fileid=3745I wrote this email in May 2014 to Criag Silverman, who at the time wrote a column for Poynter called “Regret the Error”. The topic was how we keep from making mistakes in projects that rely on a lot of records and data. I can’t find the piece that it was used in, but here’s the raw email text:  Report out the underlying records  Data definitions &amp;amp; codes  Integrity checks  Find a rabbi or a sherpa  The data diary  Report out cases  Vetting results  Editing and fact-checkingSarah Cohen The New York TimesMay 1, 2014Report out the underlying recordsAll data comes from some kind of individual record – it’s a survey response, a traffic ticket, or a payment. So  I try to track the statistics back to the underlying records and determine how they were collected and how they make their way into some kind of data system. Most still come from some kind of form, which – even if it is transmitted electronically and in bulk – still has a detailed description or a manual somewhere. Those forms tell you a lot: How much discretion do people have? What do the instructions say? Is it confusing? Then I talk to people who fill them out and people who process them once they’re filled out. I also go through hearings, audits and other criticisms of the system.Say you’re looking at crime stats: what do the underlying incident reports look like? What decisions are cops making, and what are they rewarded or punished for doing that might push close calls one way or another? What gets counted or ignored? What problems have they had in the past in responding to incidents or writing them up? I also look for items that never get into the system at all. In this case, it might be crimes that got downgraded, or people who don’t ever call the police (maybe like domestic violence victims who might lose their lease for repeated complaints.)This is a reporting job, not a data analysis job – one that too many people skip.I just did a story on deportations, and ICE only maintains the “most serious” criminal conviction – It took about 3 weeks to nail down what that meant, who assigns it and how it matters to the agents on the ground.Data definitions &amp;amp; codesI try to go through each field in the database and be sure I know what each one actually means, not just what it says, even if it seems irrelevant to what I’m doing. The names and the descriptions of codes are usually some kind of bureaucratic or computer-ese shorthand, and they often aren’t what they seem. There’s a famous example of this: old versions of the federal contracts database had a field called “obligation type”. If it was “A”, it meant the amount listed was a payment by the government to the contractor. If it was “B”, it meant that there should be a minus sign next to the amount – it was money the government got back from the contractor. Yikes.I try out a few sentences using the data and see what might be wrong with them. In the immigration example, a single person could be deported many times, but the agency wouldn’t give us anything that would let us track an individual. It meant we could never characterize the data as “people”, only “cases.”Integrity checksI try to find some kind of benchmark I should be able to hit pretty closely (or exactly). In the immigration example, the agency had published a few key statistics from the same data, and once I got the definitions down, I could match them almost exactly. There was a good explanation about why they would have changed since they published the initial figures, and they were only off by about 100 out of 300,000. Most data reporters start laughing when they see a spreadsheet of 65,536 rows - it’s the limit of older versions of Excel and usually indicates that dataset isn’t complete. (Early in the Wikileaks story, the reporters were stumped because they were missing the later months. The problem was they’d imported it into a spreadsheet with those limits. They realized it quickly, but they might not have if they weren’t diligent.)I also try to do simple frequencies on any field I care about to see how often they’re filled out and whether they seem to have any oddities. A lot of times you’ll find out no one has ever used the code you think is so interesting, or even that they have redacted the cases with a code you might care about. The Washington Post  won a Pulitzer in 1999 for a series of stories about police shootings that originated from a missing code  – the FBI had been removing justifiable homicide by police (maybe  “81”) from its Supplemental Homicide Reports for years, and Jo Craven McGinty fought to get those missing records. The story, of course, was far more than the data, but the data sparked them to look at the problem of police shootings in DC.I also look for things like missing months, zip codes that don’t exist, impossible combinations like 10-year-olds with court records, or codes that abruptly start or stop. When I find these problems, I have to report them out.Find a rabbi or a sherpaOthers know this data better than I do and I try to convince them to guide me and look over my shoulder. Ideally, there are 3-4 people who you can trust to vet your work along the way. This usually requires convincing them you’re worth their time by doing a lot of the steps above and by reading anything they’ve written on the subject. It’s also useful to find any academic literature on your topic and contact any researchers who have touched on it. They often know of projects they would have wanted to do, but couldn’t get funded.The data diaryOn longer stories, I keep a diary of the data work three ways, but different people do it differently. The goal is to make the work reproduce-able and to make sure I’ve got reasons for every decision I had to make along the way.      Use computer programs to do as much as possible, heavily commented and versioned. I haven’t gotten in the habit of saving my versions on Github, but I should – it’s a great way to be able to backtrack. It’s much more difficult to log every mouse click than to to comment computer code to say what problem I was trying to solve or question I was trying to ask, and what problems I ran into doing it other ways. It’s really easy to fix and re-run a computer program than it is to re-do mouse clicks when it turns out there was a mistake early on.        Keep a log of my interviews on the data. Invariably, you get conflicting answers or never get satisfactory answers to some of the questions. The problem is, usually no one has used the data the way you’re using it, so you have to ask them why what you are doing could be wrong – what traps are in there waiting for you? I do agree to these interviews on background. I know that others don’t, but at this point I’d rather know what I might be doing wrong, and I don’t really have any firm results yet.        Keep another log decisions I made along the way. Again on the immigration story, I had to decide what a “minor” vs. “serious” crime was, and what to do about drug convictions when it didn’t distinguish between sale or possession. I try to make every close call err on the side of the least newsworthy answer  to avoid hyping results. In this case, drug offenses were counted as “serious” all the time, because the agency claimed it was focusing on “serious” criminals and we didn’t want to undercount them when we said that most deportees weren’t.  Report out casesI describe the process as moving from lab to field and back to the lab, reporting out some cases that seem to reflect a bigger pattern. Those often turn into the anecdotes in the story. In some cases, you can look yourself up or someone you know. In others, you can look up cases that have been in the news. In others, you can go to a place and talk to some actors. When I worked on farm subsidies, we called lots and lots of farmers and asked them to go over what we thought we’d found.  We also try to find ex-employees of the agency or a company to go over the records with us. But usually, there was one case that sparked our interest in the records in the first place, so we can look up that case and find others like it.Last year, I worked on a story on police who committed domestic violence. One set of records I used were disciplinary records  for one state, which showed a huge drop in 2012. I kept asking the agency why, and what was missing, but the expert on the data said it was complete. Later, I filed a public records request for a recent case that was in the news. That’s when I learned that the entire case is secret until it goes to a hearing, which often happens 6-8 months after the complaint. Those were the missing records, but I would have never known if I hadn’t been asking about cases. (It also helps with the public records aspect of the issue – by giving us enough information to report out cases, the agency can be sure that the data isn’t misconstrued, and it reduces the agency’s workload in explaining things.)Vetting resultsI want to give the agency or the subject of the time to digest what we’ve found and seek out as many experts and stakeholders as I can to vet the results. There is always a risk that there is some kind of mistake in logic or processing or some other misunderstanding. I want to hear the reasons I might be wrong, and about anything that surprises them. In most of these projects, no one has ever done what I’ve done, so they can’t fact check for me.  One thing that has made this really important step a lot harder is that government agencies now restrict who we can talk with so much that we can’t get a real  experts to answer questions at the front end. That means we have to try to engage them at least at the back end. It’s far from ideal, but even worse when the agency just won’t let us talk with anyone but the PIO or the agency head, who may not know enough about the details to give us real feedback. We used to be able to engage with the people who were in charge of the data collection, even if it was just on background.Editing and fact-checkingI write the sections of the story that I’m responsible for when I work on a team, and go through drafts regularly to find places that the records could strengthen a point. This sometimes involves reworking the data so that it’s more precisely matching the sentences we want to write – for instance, “10 years” not “since 2002”. (In other words, cut off a year of the data.)I’m in the editing sessions or getting copies from the editor on a regular basis, as well as coordinating any data with graphics as we go along. One problem is that there are often old versions of results or spreadsheets floating around among editors, reporters and graphics folks, and they sometimes find their way into drafts over and over, after we’ve made corrections based on our vetting.For me, fact-checking involves circling every fact – whether or not it’s a number – and going back into the data and re-doing the analysis that led to that particular fact. Then I’ll pull that out into a fact-check file somewhere. At some point during the writing / editing phase, I try to retrace the entire process from start to finish. For instance, in the immigration story, the most time-consuming thing was to combine 11 spreadsheets into one database containing 3 million records. I didn’t re-do that step because I had been able to match my benchmarks after that step. But I do re-do any key tables or queries, check the code that created them, and make sure that they’ve incorporated any of the comments I got along the way. I’m also checking the graphics regularly to make sure they match what the story says and resolve any differences.",
    "url": "http://localhost:4000/cronkite-docs/assets/docs/bulletproof.html",
    "relUrl": "/assets/docs/bulletproof.html"
  },
  "1": {
    "id": "1",
    "title": "Cronkite-Mayo",
    "content": "Cronkite-Mayo Clinic data reportingMay 2018Presentations  Powerpoint from class  - Becoming a better watchdog  The AP’s Meghan Hoyer’s health care Datapalooza from the USC health care fellowship, 2017 (with permission). Her tip sheet on sources is made for California reporters, but it will give you a sense of what’s available elsewhere.Data compilations      Look through ProPublica’s data store for some cleaned datasets and links to other government sources. Start with “Vital Signs” data lookup, then consider learning how to use its API.        The mother of all regulatory sites: reginfo.gov. Search to the “Information Collection” section. To reduce the number of results, use only “active” forms. (Video to come). While you’re there, check out the “Unified Agenda” for any agency you care about. This is the list of upcoming regulatory and deregulatory actions, created for lobbyists to know what to expect in the future.        healthdata.gov is supposed to be a compilation of all HHS datasets. Look at them by component for the easiest navigation.  CMS datasets(HHS’s Centers for Medicare and Medicaid Services)CMS’s data sources are confusing. They could be found in cms.gov, medicare.gov or medicaid.gov.Standard provider level datasets  Medicare utilization public use files  Medicare consumer-oriented datasets on quality and selected utilization at https://data.medicare.gov/data  openpayments: Drug company and device payments to providers  Cost reports for Medicare-eligible institutions, including hospitals, nursing homes, renal clinics, home health care, and hospice. These are the reports that show whether they are making and spending enough to provide care. It includes general financial information on all of the institutions’ activity, not just Medicare patients.Drug price and utilizationCMS drug spending has average prices paid in Medicare Part D, Part B and Medicaid. It also has the most recent year total spending.data.medicaid.gov has more details on drug utilization.Nursing homes  A lot of people use the CMS’s Nursing Home Compare tool and data, but Propublica has made it much easier: Use its Nursing Home Inspect tool, with downloadable data of unredacted inspection forms. It has documentation on sourcing and the meaning of the files.  The “full statement of deficiencies” for April 2018. Look at the bottom of https://www.cms.gov/medicare/provider-enrollment-and-certification/certificationandcomplianc/fsqrs.html to see a newer link. (The “download” directory isn’t public, so you can’t just tour it.)  A list of state contacts for nursing home inspections and regulations.",
    "url": "http://localhost:4000/cronkite-docs/workshops/cronkite-mayo.html",
    "relUrl": "/workshops/cronkite-mayo.html"
  },
  "2": {
    "id": "2",
    "title": "Data diaries",
    "content": "The data diaryAt the Associated Press, data reporters issue a simple command when beginning a project, which sets up a standardized set of files and folders. From there, reporters’ work is centrally stored and documented in standard locations, making it easy for any one on the team to dip in and out of the project.All of the unit’s work, including its story memos, are done using standardized tools that allow for replication at any point in the project and ensure that any communication with all members of the reporting and graphics teams are looking at the same, up-to-date results.“We have the one-person bus rule,” said Meghan Hoyer, the team’s manager. If someone is hit by a bus, someone else should be able to pick up the project without wasting any time.One concession Hoyer made was to standardize the team around the R programming language. She doesn’t regret it. “It was a big lift at the time,” she said. “But now I could never go back” to overseeing projects done using less formal structure and documentation. (Note to students: AP data journalism interns are required to come with some facility in R, another good reason to learn it.)Replication and the data diaryIt doesn’t matter where you come down on the esoteric debate on replication. Your data, its analysis and the way it’s characterized in publication must be demonstrably accurate. That means understanding exactly what you did, why, where it all is and how it should be communicated to a general audience.The formal processes used by AP might not work for smaller endeavors, but anyone can put the underlying ideas to work. At the Center for Public Integrity, Talia Buford kept a simple Word document with her questions and code annotated to help her repeat her work.Enter the data diary.Think of the data work the same way you think about interview notes or transcripts and any other research for a story. You wouldn’t quote a court case without reading it and probably talking to some of the participants. You’d make sure you know where the documents are, and what people say about them. All data work should be documented in at least the same detail. Ideally, someone reading through your notes would be able to repeat your work and understand what it means.This is a note to your future self. Things happen in newsrooms. Stopping work halfway through a story and picking it up again six months later happens all the time. You should be able to pick up where you left off after briefly refreshing yourself on your work.In this module you’ll learn:  The kinds of information you need to record in a data diary or in your documentation  The questions you’ll need to be able to answer before you publish  A format for recording your work.Getting startedBefore you even start work on a new dataset, open up a new document and just start writing down what you do. For a quick daily story, you might be able to keep your work in one short document. For a longer project, you may find it easier to break your documents apart into logical pieces.In many cases, you can link to a Jupyter notebook or R markdown program that is self-documenting.  In others, you’ll need several documents to maintain a log of where you got data, who you spoke with and interviewed, what alternatives you looked at and what you decided along the way.Here are some sections that are worth considering whenever you start a story or project.Data sourcing      Where did you get the data? How do you know it’s authentic?        A description of who originally collects the data and why it exists.        List of other stories that have used this or similar data – links, advice, warnings and findings.        Academic work that has relied on the data. Names, contact information for those sources.        Alternative sources for this and similar or related datasets or documents.  Data documentation and  flawsYou can keep editing this section as you work on the problems in the data.If you found some 10-year-old children with drunk driving records, you either imported or converted the data badly or there is a mistake in how it was recorded or transmitted to you. Once you’ve found out why and fixed it, you can nix that from your diary. But if it’s a flaw in the underlying data, you’ll describe how you tried to resolve it and what you decided to do about it.      List each step you took to look for flaws. For example, “Filtered on each field and looked for missing data.” – then what you found.        What integrity checks did you make? How were they reconciled? Do your totals match reports generated by an agency? Why not? Are there 10-year-old children with drunk driving convictions? How did that happen and how will you resolve it?        Links or copies of any original documentation such as a record layout, data dictionary or manual. If there isn’t one, consider making a data dictionary with what you’ve learned.        Questions about the meaning of fields or the scope of the data.        Decisions you’ve made about the scope or method of your analysis. For example, if you want to look at “serious” crimes, describe how and why you categorized each crime as “serious” or “not serious.” Some of these should be vetted by experts or should be verified by documenting industry standards.        A list of interviews conducted / questions asked of officials and what they said.  Processing notesSome projects require many steps to get to a dataset that can be analyzed. You may have had to scrape the data, combine it with other sources or fix some entries. Some common elements you should document:      Hand-made corrections. Try to list every one, but it’s ok if you describe HOW you did it, such as clustering and hand-entering using OpenRefine. Link to any spreadsheet, document or program you used.        Geocoding. Note how many were correct, how many missing, and what you did about it.        A description of how you got messy data into a tabular form or a form suitable for analysis. For example, you may have had to strip headings or flip a spreadsheet on its head. Make sure to write down how you did that.  The good part: Your analysis      Each question you asked of your data, and the steps you took to answer it. If you use programming notebooks, write it out in plain language before or after the query or statements.        Vetting of your answers: who has looked them over, commented on them        Why they might be wrong.  Examples of documentationA published Jupyter notebook for an analysis of FEC enforcement actions from the Los Angeles Times’ data desk.  Ben Welsh, the author of that notebook, says that there are previous versions with unpublishable work.An example of a data diary kept by Talia Buford, a ProPublica reporter, when she was working at the Center for Public Integrity. She’s nicely annotated the document to show why she structures it the way she does.A 2018 Buzzfeed News repo with start-to-finish documentation of an opioid deaths story.Data smells: looking for flaws in dataWe’ll have a  module on data cleaning, but for now, here are a couple of readings that talk about dirty data.An email exchange between Sarah Cohen and Craig Silverman, now at Buzzfeed, about the process she used at The New York Times in reporting and fact-checking. This isn’t the same as a process for replication, but it discusses the kinds of things that should be in it.Ensuring Accuracy in Data Journalism, or Data Smells, by Nikolas Iubel  – Sarah Cohen, 2018",
    "url": "http://localhost:4000/cronkite-docs/general/data-diary.html",
    "relUrl": "/general/data-diary.html"
  },
  "3": {
    "id": "3",
    "title": "Arizona population exercise",
    "content": "This spreadsheet contains figures for the estimated population of Arizona counties from 2012 through 2017. It also contains the components of change.Your job is to find a story in this data by using change, percent change, percent of total to find something newsworthy. Consider looking up some stories written on similar data, either in Arizona or elsewhere, to see how reporters generally treat population data releases. One example, based on data released by the state, is from Tucson.com.As you do your analysis, consider the unit of analysis (county) and what the various components might tell you. Did a county grow because of migration from other areas, or because there was a relatively high birth rates? Is the county dying off?Make sure to read the documentation and any definitions you can find before you start.Data DocumentationSourceThe dataset was derived from the U.S. Census Bureau’s annual estimates of population of the U.S., which breaks down the change in population based on its components: Natural population change, which is births - deaths; migration, which includes net increases in immigrants from other countries (international) and other counties (domestic); and what it calls a “residual”, which is an unexplained portion of the estimated change in population.The data was downloaded from the Census’s county population site at https://www.census.gov/data/datasets/2017/demo/popest/counties-total.html. The csv file is at the bottom of that page under “Datasets”.The Census bureau uses many sources to compile these estimates, but they are not the same as a national census. The sources include vital records from state and local health department on birth and death certificates; estimates of domestic migration from tax and other records, and estimates of immigration from other countries from a variety of sources, including schools. They then try to make it all add up to the annual American Community Survey estimates at the state level.The full methodology is linked off of the main page.Changes to the file      Arizona counties and the state total were pulled out of the national file.        The data was kept for the years 2012 to 2017 to get a five-year change estimate.        Populations are kept for all of the years.        Net change in population, births, deaths, natural increase, international migration, domestic migration, net migration and residuals are the totals for the years 2013 through 2017.        The data was checked to makes sure that:       births + deaths = natural change   international + domestic migration = net migration   natural change + net migration + residual = population change   population 2012 + population change = population 2017      Reference mapIt will be easier to work with the data if you have a sense of Arizona geography, especially which counties contain the large cities and which counties are made up of tribal lands:",
    "url": "http://localhost:4000/cronkite-docs/excel/practice/excel-azpop-exercise.html",
    "relUrl": "/excel/practice/excel-azpop-exercise.html"
  },
  "4": {
    "id": "4",
    "title": "Swimming pool inspections",
    "content": "This excercises uses a database of swimming pool inspections obtained by Courtland Jeffrey at ABC15 through a public records request to the Maricopa County Environmental Services department. This website reviews exactly which pools must be inspected.Interviewing your databaseLook for a guide on the agency websiteBefore you open the spreadsheet, review the material available on the county’s website. Read the information available on what the department does, and then click on the Swimming Pool Inspections link to the left.The Weekly Report simply provides a list of the inspections conducted for a single week. Note that you can also search for a business name or address.This report should show you what each column in your spreadsheet means.What do you have?Now open your spreadsheet and start interviewing your data.Use a filter to help you answer these questions:  What makes this dataset “tidy”, or, alternatively, in what way is it “untidy”?  Note what data type is in each of the columns – are they codes, categories, numbers or free text? Is the text standardized? Are there comments of the kind you would fill into a big box on a form?  What is the date range of this dataset?  What is the unit of analysis, or can’t you quite tell?Note that this spreadsheet is formatted as a “data table”, which means you have the option of making formulas based on the column heading or based on their cell addresses.How does what you have compare to what the agency shows?If you look up a few of the addresses that you see in  your spreadsheet, you can make sure you know what each column heading means by matching the values against the online version. You can also know a little more about what was NOT provided in this dataset under this request.Note that it’s not always easy to find the right pool by looking up the name and address. For example, the Union Hills Estates “Main” pool doesn’t appear in the list of pools under that name or address. There are other pools, but none with the same Permit ID as the ones in our database:Let’s see if we can trick the Web app into giving us the proper pool to compare. In this case, try clicking on one of the existing pool numbers, then look at the URL in your browser:Change the url to one in your spreadsheet, then filter your spreadsheet for just that pool:Two of the inspections that are in the date range of our dataset are shown on this list: 2/9/2016 and 10/6/2016. Take a closer look at them and compare what is in your spreadsheet to what is on the web.If you click on the other inspection that you found in our database, you’ll see that, eight months later, a routine inspection showed that two of the violations are repeated, and that the county did nothing.On your own, look up some other interesting items that you found on your database – try looking at different kinds of inspections, different outcomes, and different statuses to see how they are reflected on the web.Jot down two or three story ideas that might emerge from an analysis of this, and two or three that would emerge if you had the data the way the county holds it – in a proper database rather than as a summary.Start asking questionsUsing your newfound deep understanding of swimming pool inspections, try answering these questions:      Which properties have had the most violations?        Find the most common violations.        Which violations lead to pool closures?  There are some things that will be hard without flagging some of the data – for example, if there was no violation, the address is still included. For that reason, you may want to add a column at the end that tests for whether there was a violation.In this case, we can say that this is an INSPECTION record, if the violation is blank. Otherwise, it’s a VIOLATION record.Going furtherCreate a unique identifier for each inspection, then group by that number to find the number of INSPECTIONS by type, rather than the number of VIOLATIONS or RECORDS. One way to do that is to use the numeric value of the dates to combine with the swimming pool ID. You can turn the date back into a number using the formula:  =TEXT([Inspection Date],&quot;00000&quot;)To put two text fields together, use the &amp;amp; symbol:   =[Permit ID]&amp;amp;TEXT([Inspection Date],&quot;00000&quot;)Now you can create a Pivot Table to show a row for every inspection:Congratulations!  You’re now a data reporter!",
    "url": "http://localhost:4000/cronkite-docs/excel/practice/excel-pivot-pools.html",
    "relUrl": "/excel/practice/excel-pivot-pools.html"
  },
  "5": {
    "id": "5",
    "title": "Excel",
    "content": "",
    "url": "http://localhost:4000/cronkite-docs/excel",
    "relUrl": "/excel"
  },
  "6": {
    "id": "6",
    "title": "General resources",
    "content": "",
    "url": "http://localhost:4000/cronkite-docs/general",
    "relUrl": "/general"
  },
  "7": {
    "id": "7",
    "title": "Home",
    "content": "Most of the materials for the Cronkite School’s data journalism course taught by Knight Chair Sarah Cohen are kept here. It’s also a holding center for some other presentations, like FOIA workshops.This site is replacing a lot of the other sites I’ve made over the years to collect data reporting and public records materials. I’m trying to get more organized. If you’re looking for those, you’ve probably been redirected here. It’s also an attempt to rein in dead links and outdated materials that no longer work.The sections are:General resourcesA collection of data reporting resources, including re-introductions to math and stats, some best practices and links to stories and projects that can exemplify the data reporting genre, especially in investigative and enterprise journalism.There is also a series of links on background in data journalism.ExcelTutorials and exercises using Excel for daily chores. These are conceptual as well as technical – you’ll find some of those concepts in repeated in other sections.R statsSome resources and markdown files for learning basic R to replace some of your Excel workflow.Specialized toolsAnything that is used for one purpose, such as OpenRefine for data cleaning, or the Chrome Scraper for scraping.WorkshopsWhere I stash my presentations for various workshops. Some are links to other reposPublic recordsResources to understand and acquire public records using U.S. federal and state laws.",
    "url": "http://localhost:4000/cronkite-docs/",
    "relUrl": "/"
  },
  "8": {
    "id": "8",
    "title": "Math and stats",
    "content": "",
    "url": "http://localhost:4000/cronkite-docs/general/math-stats/math-stats.html",
    "relUrl": "/general/math-stats/math-stats.html"
  },
  "9": {
    "id": "9",
    "title": "Newsroom math and stats review",
    "content": "  Statistics are people with the tears washed off  - Paul BrodeurJo Craven McGinty, then of The New York Times, used simple rates and ratios to discover that a 6-story brick New Jersey hospital was the most expensive in the nation. In 2012, Bayonne Medical Center “charged the highest amounts in the country for nearly one-quarter of the most common hospital treatments,” the Times story said.To do this story, McGinty only needed to know the volume of the procedures reported by the government and the total amount each hospital charged. Dividing those to find an average price, then ranking the most common procedures, led to this surprising result.The basicsUsing averages, percentages and percent change is the bread and butter of data journalism, leading to stories ranging from home price comparisons to school reports and crime trends. It may have been charming at one time for reporters to announce that they didn’t “do” math, but no longer. Instead, it is now an announcement that the reporter can only do some of the job. You will never be able to tackle complicated, in-depth stories without reviewing basic math.The good news is that most of the math and statistics you need in a newsroom isn’t nearly as difficult as high school algebra. You learned it somewhere around the 4th grade. You then had a decade to forget it before deciding you didn’t like math. But mastering this most basic arithmetic again is a requirement in the modern age.In this module, you’ll learn to:  Overcome your fear of numbers  Integrate numbers into your reporting  Calculate change in a list of items  Use different types of averages as summaries of a list of items.Overcoming your fear of mathWhen we learned to read, we got used to the idea that 26 letters in American English could be assembled into units that we understand without thinking – words, sentences, paragraphs and books. We never got the same comfort level with 10 digits, and neither did our audience.Think of your own reaction to seeing a page of words. Now imagine it as a page of numbers. Seasick yet?Instead, picture the number “five”. It’s easy. It might be fingers or toe or it might be one team on a basketball court. But it’s simple to understand.Now picture the number 275 million. It’s hard. Unfortunately, 275 billion isn’t much harder, even though it’s magnitudes larger. (Remember this: 1 million seconds goes by in about 11 days. 1 billion seconds goes by longer than you’ve probably been alive, or more than 35 years.)So the easiest way to get used to some numbers is to learn ways to cut them down to size, by calculating rates, ratios, percentages and rounding off.This video will give you a more in-depth pep talk on getting used to numbers.Put math in its placeFor journalists, numbers – or facts – make up the third leg of a stool supported by human stories or anecdotes , and smart or insightful insight from sources.  They serve us in three ways:      As summaries. Almost by definition, a number counts something, averages something, or otherwise summarizes something. Sometimes, it does a good job, as in the average height of Americans. Sometimes it does a terrible job, as in the average income of Americans. Try to find summaries that accurately characterize the real world.        As opinions. Sometimes it’s an opinion derived after years of impartial study. Sometimes it’s an opinion tinged with partisan or selective choices of facts. Use them accordingly.        As guesses. Sometimes it’s a good guess, sometimes it’s an off-the-cuff guess. And sometimes it’s a hopeful guess. But even the most accurate of numbers can be guesses, such as the 2017 election in Virginia that swung the state legislature by a single vote in Newport News. If there are slight differences between numbers, maybe they’re not worth writing about.  Once you find the humanity in your numbers, by cutting them down to size and relegating them to their proper role, you’ll find yourself less fearful. You’ll be able to characterize what you’ve learned rather than numb your readers with every number in your notebook. You may even find that finding facts on your own is fun.Reading and viewing      Listen to the lecture on YouTube on overcoming your fear of numbers.        Read “Numbers in the Newsroom,” a $10 beat book from Investigative Reporters and Editors. Concentrate on the first two chapters.        Matt Waite’s math review        “Avoiding Numeric Novcain: Writing Well with Numbers,” by Chip Scanlan, Poynter.com  How high school algebra won a Pulitzer PrizeIf you were at all paying attention in pre-college science classes, you have probably seen this equation:d = rt or distance = rate*timeIn English, that says we can know how far something has travelled if we know how fast it’s going and for how long. If we multiply the rate by the time, we’ll get the distance.If you remember just a bit about algebra, you know we can move these things around. If we know two of them, we can figure out the third. So, for instance, if we know the distance and we know the time, we can use algebra to divide the distance by the time to get the rate.d/t = r or distance/time = rateIn 2012, the South Florida Sun Sentinel found a story in this formula.People were dying on South Florida tollways in terrible car accidents. What made these different from other car fatal car accidents that happen every day in the US? Police officers driving way too fast were causing them.But do police regularly speed on tollways or were there just a few random and fatal exceptions?Thanks to Florida’s public records laws, the Sun Sentinel got records from the toll transponders in police cars in south Florida. The transponders recorded when a car went through a given place. And then it would do it again. And again.Given that those places are fixed – they’re toll plazas – and they had the time it took to go from one toll plaza to another, they had the distance and the time.It took high school algebra to find how fast police officers were driving. And the results were shocking.Twenty percent of police officers had exceeded 90 miles per hour on toll roads. In a 13-month period, officers drove between 90 and 110 mph more than 5,000 times. And these were just instances found on toll roads. Not all roads have tolls.The story was a stunning find, and the newspaper documented case after case of police officers violating the law and escaping punishment. And, in 2013, they won the Pulitzer Prize for Public Service.All with simple high school algebra.Exercises      In class: Create a spreadsheet with basic numeric information about your school, such as enrollment this year and last; graduation rates; and tuition. Use basic math to show change, percent change and averages.        Imagine it is Jan. 1, 2018 and you are tasked with writing the annual weather story, summarizing the high and low points of the previous year. Using this  daily summary of temperatures, rain and wind for Phoenix, try to find three interesting facts for your story. If you want to download your own data from NOAA, choose “Local Climatalogical Data,” and keep only the rows that refer to “SOD,” or “Summary of Day”.        Download the population estimates for the nation and find the fastest-growing and fastest-shrinking counties in the nation over  past five years.  – Sarah Cohen and Matt Waite, July 2018",
    "url": "http://localhost:4000/cronkite-docs/general/math-stats/newsroom-math.html",
    "relUrl": "/general/math-stats/newsroom-math.html"
  },
  "10": {
    "id": "10",
    "title": "Links to source data for doctoral students",
    "content": "Outside data sources for doctoral students      Social Explorer is a much easier way to get at Census and related data than going through the Census bureau. It’s a subscription service that is available any time you’re connected through the school’s IP.  It includes block group level 5-year ACS files, decennial census and some historical data other sources.        IPUMS is a project out of the University of Minnesota that collects microdata and tries to line it up across years. This means you can compare Census results for some geographic areas over a very long time. Most of the time, you can generate your results online, which takes care of weighting and error testing. In some cases, you’ll have to download the data and create summaries yourself. Of particular note is the Time-Use survey and the CPS voter supplement.        General Social Survey has been taken every other year since 1972, and include a varying set of questions on social issues. It’s a difficult site to use, and trend data is shown online only for some predetermined issues. Be careful with the weighting - in two years, they oversampled African-American respondents, which means you have to remove that sample code to make years comparable. Using wtsall as the weight will take care of these problems. (example using hours of tv)        enigma.com wants to be the Google for public records, and it has aggressively sought out some datasets from government agencies. (Example: The minority report on Facebook ads allows you to look at the data submitted to Congress during the investigation) One of its great strengths is that it takes care to give you the lineage of all datasets.        data.world wants to be the Facebook of data, where people can share their data and insights. It’s all over the place – no one makes any effort to curate it, or to enforce credibility standards. But if you find something there, you can usually follow it back to the original source.        github.com is where a lot of people stash their data, and by default it’s public. A Google search usually doesn’t search the datasets held inside Github’s world - you normally need to search there. It’s also useful to look for news organizations’ github pages – this is where they make data public that they’ve used in stories. (There are some other places, but this is the most common.)        Google’s new dataset search makes it a little easier to find standard datasets, but it is just as hit or miss as the rest of Google.        Roper Center for Public Opinion Research is an archive of reputable polling results. Most organizations contribute them to Roper after some time has passed, but it’s a useful place to see what questions on your topic have been asked before, and by whom. One way to use it is to do a new survey based on the same questions if you need a comparison. Search poll questions using the  ipoll search. Their datasets are mainly historical or esoteric.  ",
    "url": "http://localhost:4000/cronkite-docs/workshops/phd-sources.html",
    "relUrl": "/workshops/phd-sources.html"
  },
  "11": {
    "id": "11",
    "title": "R for journalism",
    "content": "R resourcesHere are several other sources for you to review if you want to try something different on your own:  Matt Waite’s sports data analysis and visualization course from the Univ. of Nebraska.  R for Data Science, an online textbook written by Hadley Wickham, inventor of the tidyverse.  Intro to Data Science for the Social Sector, Jesse Lecy, from the ASU Program Evaluation and Data Analytics. This is much more a startup in R than a course in program evaluation.  First 5 chapters of Sharon Machlis’ Practical R for Mass Communication and Journalism",
    "url": "http://localhost:4000/cronkite-docs/r-stats/rstats.html",
    "relUrl": "/r-stats/rstats.html"
  },
  "12": {
    "id": "12",
    "title": "Workshops",
    "content": "Holding page for index of workshops.",
    "url": "http://localhost:4000/cronkite-docs/workshops",
    "relUrl": "/workshops"
  },
  "13": {
    "id": "13",
    "title": "Simple data diary for Excel",
    "content": "A simple data diary for ExcelA simple data diary for the beginning of the Excel math review module might look something like this:Data sourceOriginal file downloaded as a xx-page PDF from the Phoenix city budget site at https://www.phoenix.gov/budgetsite . The link was https://www.phoenix.gov/budgetsite/Budget%20Books/SummaryBudget2017-18.pdf. It’s undated as far as I can tell.The key tables were on pages 182-183 – that is listed as the “Expenditures” by program.Using Acrobat, extracted out those pages into a new file, ~/Documents/examples/ phx_budget_2017_table.pdfI tried to extract the tables using different programs: Able2Extract, Adobe Acrobat, Tabula. Then I realized that it is an image, not a text, pdf. Went back and OCR’d it using Adobe Acrobat, but when I sent it to a csv, it was a mess.I decided to type in the numbers myself rather than try to clean it up.The original spreadsheetCreated a blank spreadsheet called ~/Documents/examples/phx_budget_summary.xlsx .Added a notes page to document where I got it from.categories sheet: Typed in the numbers from the 2016 actual, 2017 estimated and 2018 budget category totals.Selected them and checked against the totals shown at the bottom of the page. They were right, except for 2018. Then I realized I hadn’t typed in the “contingency” line. I decided not to type it in at all. The reason is that, the way I understand it for now, this is money they hope not to spend. It’s a reserve fund for something that’s unexpected that comes up. There’s no category for it in the past because if it was spent, it went into the proper category. Add to the TO DO list to find out if that’s the right way to treat it.Did the same thing for the individual programs on another sheet, but entered the categories into their own column, in a tidy fashion.Checked against the originals. They matched. Made sure to un-format any numbers so that if I want to export to another program, they’ll come in correctly.This spreadsheet won’t be changed unless the data is updated.CleanupFormatted the numbers as dollars.Widened the columnsAdded a unique identifier to the detail rows in categories in case I need to sort.Created a row that checks the sums of the detail against the sum provided by the city.Saved the spreadsheet as phx_budget_summary_sc01.xlsxQuestions  What is the money for contingency? How has it been used in the past?  What does “estimated” mean for 2017 – don’t they know how much was actually spent? When was this created?  Is there any reason that comparing the estimated 2017 to budgeted 2018 would be misleading?Keep goingYou can finish the rest yourself, but the key is that everything you’ve done is logged, and anyone reading this can follow what you did. Including yourself.",
    "url": "http://localhost:4000/cronkite-docs/assets/docs/xl-mathreview-datadiary.html",
    "relUrl": "/assets/docs/xl-mathreview-datadiary.html"
  },
  "14": {
    "id": "14",
    "title": "Excel math review",
    "content": "Math and stat review using ExcelBefore you start, you should be sure to read the more general math and stats refresher regardless of whether you’re using Excel, R or something else.The math review is going to use the City of Phoenix’s budgeted spending for the 2018 fiscal year, compared with previous years.  (Source: https://www.phoenix.gov/budget/annualbudget)  Files for this tutorial  Get into good habits  Common spreadsheet arithmetic          Check the government’s math with SUM      Change in spending      Percent change      Parts of a whole: percent of total        While we’re at it: two kinds of averages  The final spreadsheetFiles for this tutorial  A data diary for the processing that went into this spreadsheet for this tutorial.  The Excel spreadsheet for this tutorial.Get into good habits      Right-click on this link to the Phoenix budget summary that I prepared for you, and choose “Save As” to keep a copy on your computer rather than opening it directly into Excel. Once you’ve done that, right-click on the Download area of your browser and look for the file on your computer. Don’t double-click – we’re going to ask you to get out of that practice as much as possible, understanding that it’s a natural instinct.        Start your documentation worksheet or document and describe, in plain language, every question you’ve asked, every answer and its source, and every step you’ve taken.        Save a working copy with some sort of sequential name in a folder you can find again.        Is there documentation that provides the source of the data, and the meaning of each column?  Can you get it from the original document or dataset?        Check your corners - how far to the right and how far down does the data go? Is it a contiguous square? Is it “tidy”? Does every column refer to one thing, and every row one instance of that thing?        Does it have exactly 32,767 or 65,536 filled in rows; does it have exactly 256 filled in columns?        Does it have unique identifiers for each row? If not, make them in a way that will guarantee you can re-sort back into the original order.        Are totals or notes mixed into the same contiguous area as detail? If so, separate them from the data.  Common spreadsheet arithmeticThe budget document shows three years’ of data: The actual spending in the fiscal year that ended in 2016; the spending that was estimated for the end of fiscal year 2017; and the proposed spending for fiscal year 2018. The first page of the document shows these amounts for broad spending categories.You may want to widen the columns and format the numbers before you start:Check the government’s math with SUMOur first job is to make sure the government has provided us data that adds up. To do that, we’ll SUM all of the departments’ spending.To add up the numbers from 2016, enter the following formula in cell C11, just below the number provided by the government:  =SUM(C2:C8)  and hit the enter keyCopy that formula to the right. Notice how the formula changes the addresses that it is using as you move to the right – it’s adjusted them to refer to the current column.What’s wrong? The numbers for the budget 2018 don’t add up. (Hint: look at the page called “notes” for an explanation.)Change in spendingThe increase or decrease in projected spending from 2017 to 2018 is just the difference between the two values, beginning in cell F3  new-old, or  =E2-D2When you copy  it down, note how the references to each row also adjusted. In line 3, it’s E3-D3, and so on. Excel and other spreadsheets assume that, most of the time, you want these kinds of adjustments to be made.Percent changeWe can’t tell the rate of growth for each department until we calculate the percent change from one year to another. Now that we already have the change, the percent change is easy. The formula is:  ( new - old ) / oldWe’ve already calculated the new-old part, so now all that’s required is to divide by the old value. In grade school, you also had to move the decimal place over two spots, since the concept of percent change is “out of 100”. Excel formats will do that for you.Remember, it’s always (new-old)/old , NOT the big one minus the little one. Doing it correctly, the answer could be negative, meaning the value fell.When you’re done, you can format the answer as a percentage to get it into whole numbers.Until you get used to it, there’s no harm in doing these calculations step by step. Excel won’t complain if you have extra columns. You can always hide them.It’s also worth comparing the picture you get by looking at raw numbers vs. percentages. In our case, the budget for public safety is expected to rise by a whopping $102 million, but it’s a smaller percentage increase than other, smaller departments.Parts of a whole: percent of totalWe’d also like to know what portion of the total spending is eaten up by each department. To do that, we need the percent of total.In our case, let’s use the total that the government gave us. In practice, you’d have to decide what to do if your figures didn’t match those provided by officials. You can’t assume that the total is wrong – you could be missing a category, or there could be a mistake in one of the line items.The formula for percent of total is:  category / totalAgain, Excel will multiply by 100, or move the decimal place over for you once you format.But you have a problem: You either have to type in each row, or you get something like this if you try to copy:Excel has done its magic, adjusting the location of both the numerator and the denominator when you copied. You don’t have to type in each formula one by one, though. Instead,  you’ll use anchors, known in spreadsheets as “absolute references”. Think of a dollar sign as an anchor or stickpin, holding down the location of part of your formula. If you put the stickpin before the letter in the formula, it holds the column in place. If you put it before the number, it holds the row in place. If you put it in both places, it holds the cell in place.So our new formula for the percent of total is:While we’re at it: two kinds of averagesAlthough it doesn’t make a lot of sense in this context, we’ll go ahead and calculate the average or mean size of each department, and then calculate the median size.Simple average, or meanA simple average, also known as the mean, is skewed toward very high or very low values. Its formula is    sum of pieces / # of pieces that were summedBut in Excel, all we need is the word AVERAGE:    =AVERAGE(C2:C9)MedianThere’s not really a good formula for the median. It’s the middle value of a list, once they’ve been put in sorted order. (If there is an even number of values, it’s the average of the two middle values.) This just treats a very high or very low value as just another number, and it doesn’t affect the summary very much.For example, if we have five people with the following incomes:    $8,000   $10,000   $12,000   $15,000  $500,000The average, $109,000, will not be a good summary of the list. In fact, no one on the list makes anything like that. But the median, $12,000, reflects the middle of the pack. With America’s income inequality, this is common in anything measured in dollars like home values or incomes.In Excel, you can get the median of a list of numbers by just using the formula, MEDIAN()  = MEDIAN(C2:C9)The final spreadsheetAt this point, write out a few questions you might want to ask an official if you only have a few minutes.  Now that you have some data that might point to news, you can use it to ask the official to confirm your analysis and explain the underlying reasons.",
    "url": "http://localhost:4000/cronkite-docs/excel/xlguides/xl-mathreview.html",
    "relUrl": "/excel/xlguides/xl-mathreview.html"
  },
  "15": {
    "id": "15",
    "title": "Excel refresher",
    "content": "  Spreadsheets and reporting  Re-learning Excel from the ground up          The spreadsheet grid      Mouse shapes      Selecting cells and areas      Entering data      Locking in headings      Formatting tricks        Best practices          Open, don’t double-click      First look - getting to know your data        Keyboard shortcutsSpreadsheets and reportingYou may have learned how to use Excel or Google Sheets in grade school or high school to make charts or present tables, but reporters use spreadsheets in different ways.The key reasons for reporters to use a spreadsheet are:  To create our own databases that so that we can sort, filter and count events. Examples include a long-running court case; the details of each opioid death in a city; a list of police shootings and their documents; or even a list of your own public records requests or contact log.  To use data created by others for fast, simple analysis and data cleanup. Many government agencies provide their information in spreadsheet form, so you’ll need to get used to using it.  To perform simple, straightforward analysis on data and share with team members. This is becoming less common as more reporters learn programming languages, but it’s still common in newsrooms to share data, especially through Google Sheets.We’re going to work with Excel because it is still far more robust than Google sheets for much of our work. Google sheets are difficult to navigate, have limited options for filtering and have other limitations. However, for some things – especially interacting with web pages elsewhere and sharing with others – they’re much more robust.Some reporters flinch at typing in 30 or 100 entries into a spreadsheet. You shouldn’t. If you learn to take notes in a structured way, you’ll always be able to find and verify your work. If you try to calculate a sum of 30 numbers on a calculator, you’ll have to type them all in at least twice anyway. And getting used to these easy tasks on a spreadsheet keeps you fluent for when you need to do more.Re-learning Excel from the ground upThe spreadsheet gridWhen you start up a spreadsheet, you’ll see letters across the top and numbers down the side. If you ever played Battleship, you’ll recognize the idea – every little square, or cell, is referenced by the intersection of its column letter and row number:B2 is the cell that is currently active. You can tell because it’s outlined in the sheet and it’s shown on the upper left corner.Mouse shapes      BFWPS: The Big Fat White Plus Sign. This is the default shape, and you can never get into trouble when you see it.         The Copy Tool, or the thin black cross. When you see this, you’ll copy anything that’s selected. This can be good or bad.         The Evil Hand. (In Windows, this is the Evil Arrow). If you use this symbol, you will MOVE the selection to a new location. This is very rarely a good idea or something you intend.   Selecting cells and areasSpreadsheets act only on the cells or regions you have selected. If you begin typing, you’ll start entering information into the currently selected cell.To select: Hold the BFWPS over the cell and clice ONCE – not twice. Check the formula bar to make sure you’ve selected what you think you’ve got. You can also look at the bottom right of your spreadsheet for more information.To select a group of cells and act on them all at once: Hover the BFWPS over one corner, click ONCE and drag to the diagonal corner. Make sure the Evil Hand is nowhere to be seen. The entire area will be shaded in except for the currently selected cell. Look at the upper right corner to see how many rows and columns you selected.To select a column or row : Hover the BFWPS over the letter at the top of the column. For a row, hover it over the row number in the margin .Entering dataSelect the cell and start typing. The information you type won’t be locked into the cell until you hit the Return / Enter key, or move your selection to another cell. Hit “Escape” to cancel the entry.You can’t do a lot of things while you’re editing, so if you have a lot of greyed out menu items, look at your formula bar to see if you are still editing a cell.If you’re having trouble getting to a menu item or seeing the result of your work, try hitting “Escape” and try again. You may not have actually entered the information into the sheet.Locking in headingsAs your spreadsheet grows vertically with more rows, you’ll want to be able to see the title all the time. When it grows vertically with more columns, you’ll probably want to see what row you’re looking at by name whenever you can. This is called “Freezing Panes” – you freeze part of the page so it stays in place when you move around.Select the corner that you want frozen. For example, if you want the first three columns frozen (A:C) and the first row frozen (1), then select the cell in D2. This is the first cell that will move, and everything to the left of it and above it will stay on the screen.Formatting tricks      Use the buttons or the format dialog box to make numbers easier to read.        If a column is filled with a lot of text, select the column and look on the Home ribbon next to the formatting area for “Wrap Text”. This means that when you double-click to widen a column, it will get taller, not wider. This is good when you need to save valuable real estate on the screen.  Best practicesThere are several best practices we’ll be using throughout the course, and you’re expected to follow them and catch errors that they might show you. All of this is related to interviewing your data the same way you’d interview a person.Open, don’t double-clickDouble-clicking on files to open them is never a great idea. We all do it and we all find some day that we regret it. Getting used to doing it the long way will help you in the future, not just in Excel but in other programs.As an example, double-clicking on a computer program like Python or R will run the program – it won’t give you a way to edit it. Double-clicking on Excel might try to open a corrupted or extremely large file.Opening the file forces you to pay attention to where the file resides in your computer. That way  you always know that you’re using the right version, not some version that was stuck on your desktop or in some other place by mistake.First look - getting to know your dataWe’ll go over other best practices as we move along, but for now you should spend some time getting to know your data.  Save your workbook under a new name and work only on that copy.  Check your corners – look at the top left and bottom right. Is the data all in one area? Are there footnotes or other non-data sections mixed in? We’re going to want to fix that later.  If the spreadsheet shows #### instead of words or numbers, widen your columns. If it shows 7E-14 or something like that, format them as numbers, not “General”.  Add some headings and id numbers if necessary.This video goes through the first steps you’ll usually take when you have a new dataset. We’re going to go over the concept of “tidy data” later.You should follow along using the same datasest as on the video.Keyboard shortcutsFor Mac users, it’s much easier to use Excel if you override the action of function keys while you’re in the program. In your Mac’s System Preferences, choose Keyboard, and select the box that says, “Use F1, F2, etc. as standard function keys.”Once you’ve done that, these keyboard shortcuts will work:            To do this      Windows or IMac      Macbook                  Edit a cell      F2      Ctl-U or F2              Toggle between absolute and relative references      F4      Ctl-T or F4              Insert cut cells      Ctl+      Ctl+              Delete a cell      Ctl-      Ctl-              Select the top left of a spreadsheet      Ctl-Home      Ctl-Fn-Left arrow              Move to the bottom right of a spreadsheet      Ctl-End      Ctl-Fn-Right arrow              Select a region (a contiguous rectangle of cells that are filled out)      Ctl -*      Ctl-Shift_spacebar      You should practice getting around a spreadsheet efficiently, since scrolling with the mouse while selecting is a lesson in frustration.",
    "url": "http://localhost:4000/cronkite-docs/excel/xlguides/xl-refresher.html",
    "relUrl": "/excel/xlguides/xl-refresher.html"
  },
  "16": {
    "id": "16",
    "title": "Tidy data",
    "content": "  Tidy data          Tidy example      Not so tidy        Understanding data typesTidy data“Like families, tidy datasets are all alike but every messy dataset is messy in its own way..” – Hadley Wickham, with apologies to Leo TolstoyHadley Wickham, who has done more to popularize the R programming language than almost anyone, wrote a seminal paper in 2014 called “Tidy Data”, which tackled the unspoken problem in data analysis: what does “clean” data mean, and what does “dirty” data mean?In it, he defined tidy data in this way:      Every column is labeled and represents a variable, or something that differs from case to case. Examples include peoples’ names, counties, zip codes, height, age, income, or year.        Every row, which may or may not be labeled, represents an observation, or an instance of each of the variables. An example might be your name, the county and zip code you live in, your height, age, income, and what year it is today.        Each type of observational unit is in its own table, such as a page in an Excel file or a data frame in the R language. This suggests that every observation should be a the same unit of analysis. For example, there can be information about every student at your school in one table, and information about every department in your school in another.  In other words, each column means one thing, each row is an instance of that thing. It means you’d rarely type two separate things into one cell, such as two names or two addresses. It also means you’ll often have a tall, narrow dataset – one with a few columns but many rows – rather than the short and wide datasets you often see. This makes it easy to sort, filter, and group your data into other information.It’s always easy to turn these tidy datasets into another form. It’s often difficult to turn messy datasets into something tidy.This sometimes looks repetitive. That’s good – it give you something consistent to summarize.Tidy exampleHere’s an example, showing the beginning of a file obtained from New York State showing the names, locations and salaries of judges in the state’s Supreme Court (the main trial court in New York):It follows the simple rule that every column always means one and only one thing, and every row is an instance of that thing at the same level of analysis – the employee.It’s not perfect. The position titles don’t really show their level, but instead are sometimes used to show districts. In this sense, it’s not quite tidy: separating the title from the district would make it more useful.Not so tidyWhen you request data from the government, or seek out data on the Internet, you should look for tidy data. It is often the most pure form of the information available – it hasn’t been compiled into a report, or put together to make a nice printout. Instead, it is usually close to the way it’s been stored in the underlying database.Think of this when you see forms in the wild. They are often pretty tidy! A parking ticket is one instance of a thing, and each box filled out or left blank on the ticket is a characteristic of that thing.Sadly, the information and datasets you receive from others will often NOT adhere to tidy principles. Government “datasets” often have a lot of extra verbiage at the top and bottom, or are done in a hierarchical fashion, mixing detail and total at the same time. In this example, the Census Bureau seems to anticipate that you will print this data, not use it:If you just needed a few numbers from the release, this table is perfectly adequate. But if you wanted to combine it with other data or sort it in any way, it’s nearly useless.  When you come across data that looks like this – with subtotals and different topics broken down the side, and many figures going across the top – look for other formats that might have been released, or talk with the agency to get something more useful. In this case, we’d look for the underlying data that created these tables.Here’s another example, this time from the Ohio Secretary of State, that lists the results of the 2016 election. Each page is one type of race – Congress, president, etc. – and each column shows the result for a candidate within a race. The rows are sometimes the precinct, and sometimes the total.There are totals mixed in with the precincts, and each of the candidates are listed left to right for every Congressional race. This makes it easy to read if you want to see who won. But each precinct would only have one race for U.S. Senate and one for the House, meaning that most of the values listed in this very, very wide spreadsheet are zero.Take out a piece of paper and sketch what a more tidy version of this spreadsheet might look like – what are the column headings, what does each row represent, and how might it be put together? It’s actually more complicated than it seems. Just remember that, so long as each table you create has a unique identifier that represents just one thing, you can always link them together.(Computer scientists shouldn’t confuse this with the “3rd normal form”. This is much less rigid about breaking out tables whenever there is repetition, but it does adhere to the idea of a single unit of analysis in each table.)This is an excellent exercise for you to do whenever you are working on data: envision success. If you had what you wanted, what might that look like?Here is an example spreadsheet of a series of ways that governments have provided data when it was requested. Go through them and think about how they might be useful – what might they look like? How could you use them to sort and filter? How could you add or count them effectively?Here’s a video that goes through what is wrong with them and how we fixed it.Understanding data typesWhen you start working with tidy data, there is also an unspoken rule: Each column should contain the same type of data, often broken into three categories: text, numbers and dates.This video goes through the basic types of data that you’ll find within a table, like an Excel worksheet. As you get into programming, there are much more complicated data types that are really powerful. For example, a data type of “data frame” is used in R and Python to act like a data table. A json object can define a whole database in nested text. For now, though, just understanding exactly what numbers, text and dates are will make things clearer – including what happens if you don’t pay attention to them.",
    "url": "http://localhost:4000/cronkite-docs/excel/xlguides/xl-tidydata.html",
    "relUrl": "/excel/xlguides/xl-tidydata.html"
  },
  "17": {
    "id": "17",
    "title": "Excel guides",
    "content": "",
    "url": "http://localhost:4000/cronkite-docs/excel/xlguides",
    "relUrl": "/excel/xlguides"
  },
  "18": {
    "id": "18",
    "title": "Excel practice",
    "content": "",
    "url": "http://localhost:4000/cronkite-docs/excel/xlpractice",
    "relUrl": "/excel/xlpractice"
  }
}


          
        </div>
      </div>
    </div>
  </div>
</html>
